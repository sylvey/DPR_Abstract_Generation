{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hgw3GTXLLw0"
   },
   "source": [
    "## ðŸ¤— Finetune **Longformer Encoder-Decoder (LED)** on 8K Tokens ðŸ¤—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7-QHmRiAMB9"
   },
   "source": [
    "The *Longformer Encoder-Decoder (LED)* was recently added as an extension to [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150) by Iz Beltagy, Matthew E. Peters, Arman Cohan.\n",
    "\n",
    "In this notebook we will finetune *LED* for Summarization on [Pubmed](https://huggingface.co/datasets/viewer/?dataset=scientific_papers). *Pubmed* is a long-range summarization dataset, which makes it a good candidate for LED. LED will be finetuned up to an input length of 8K tokens on a single GPU.\n",
    "\n",
    "We will leverage ðŸ¤—`Seq2SeqTrainer`, gradient checkpointing and as usual ðŸ¤—`datasets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B19PhgrCHM1"
   },
   "source": [
    "First, let's try to get a GPU with at least 15GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JnoCUoL-2Jz"
   },
   "outputs": [],
   "source": [
    "# crash colab to get more RAM\n",
    "# !kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZ11Va-qCp96"
   },
   "source": [
    "To check that we are having enough RAM we can run the following command.\n",
    "If the randomely allocated GPU is too small, the above cells can be run\n",
    "to crash the notebook hoping to get a better GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9IkphgF-90-",
    "outputId": "db67938b-fc8c-42a2-ec57-84baa4bba514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 18 15:56:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   68C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHSLE5TdC7RL"
   },
   "source": [
    "Next, we install ðŸ¤—Transformers, ðŸ¤—Datasets, and `rouge_score`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzh-JNaUK3Y_"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets==1.2.1\n",
    "!pip install transformers==4.2.0\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u9twLMqYEzT"
   },
   "source": [
    "Let's start by loading and preprocessing the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ODLQ8MUJfmi4"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEZ20fa9DP4W"
   },
   "source": [
    "Next, we download the pubmed train and validation dataset ([click to see on ðŸ¤—Datasets Hub](https://huggingface.co/datasets/scientific_papers)). This can take a couple of minutes **â˜•** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bR9A9aaMci2i",
    "outputId": "2a5474a8-cfc0-4258-e1fc-a236ef9666da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scientific_papers (/root/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/043e40ed208b8a66ee9e8228c86874946c99d2fc6155a1daee685795851cfdfc)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = load_dataset(\"scientific_papers\", \"pubmed\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GRz0rksYb3h",
    "outputId": "ef795a2a-ac3b-467d-eb6c-25b68c35c86c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scientific_papers (/root/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/043e40ed208b8a66ee9e8228c86874946c99d2fc6155a1daee685795851cfdfc)\n"
     ]
    }
   ],
   "source": [
    "# val_dataset = load_dataset(\"scientific_papers\", \"pubmed\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWM_4AChFnpz"
   },
   "source": [
    "It's always a good idea to take a look at some data samples. Let's do that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eaz72rzWGBAK"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=4):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrwXZ_LBGLwt"
   },
   "source": [
    "We can see that the input data is the `article` - a scientific report and the target data is the `abstract` - a concise summary of the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkDoz13UB3gY"
   },
   "source": [
    "Cool! Having downloaded the dataset, let's tokenize it.\n",
    "We'll import the convenient `AutoTokenizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R-gvC8jiYtS_"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gst7xqXECbRc"
   },
   "source": [
    " and load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "c3c556400c814a9082d6e271088c3ead",
      "a3654837bcea41feb5276522e1e303fd",
      "dbca7f5762804be0b0e292b81d0c7e4e",
      "e08d14bfc9d4413fbf1bdf95e4d50c61",
      "a45379ba9d814176a825fa5314d51616",
      "629aaa73de364f60abaad1a667a93e0e",
      "9c9ec3a0b4bf4220964e4899bbc57f32",
      "a771005dce184befb9e944790b68c85c",
      "987634ba7143482a9e83b2458bdc6867",
      "28d647bf76134a2b8dffb7c516c3e18f",
      "c42d012db3d04a80bb4ba96b9719471c",
      "f2bfe910f06f4657a8b12cbe3c01d0dd",
      "26a414921849456a90c57359ec1bcd29",
      "31b6f63eb7b142fc880e20348884a3cb",
      "fd86b38ac6d14d4c81100035a6fc03ea",
      "e6d31003abdd4eb0905110d869fad1a1",
      "27e55c80741f4303948ee2187fc9dc84",
      "b3ceb8afd6dd467f9375004a95cfc6bc",
      "fe121869fe3c410f9f0355035a2f5a95",
      "7392742aa0714f89ad05f4909fe4f04e",
      "cb36dd97ef21418f997ec9fda5553d92",
      "d2161cab5e0a4d42a44347f6fad2aec1",
      "b3d4b5056c884b488753de076e9d883a",
      "8df309486b4d48a794003c00db6cf674"
     ]
    },
    "id": "jpUr9QeebZ-n",
    "outputId": "d956cbb1-adf0-48cc-9a56-24e64892fcc9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c128f0f181484f4b99f5211cd0592cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9c8f90b84e4c0e856af7de8bd96083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb174a6050642b19274ebd09a6f40d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f638001044904b86a9747641b4761f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9cac1c74484ec8bd61ac5c0f2ca010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhQeQg3oCcL-"
   },
   "source": [
    "Note that for the sake of this notebook, we finetune the \"smaller\" LED checkpoint [\"allenai/led-base-16384\"](https://huggingface.co/allenai/led-base-16384). Better performance can however be attained by finetuning [\"allenai/led-large-16384\"](https://huggingface.co/allenai/led-large-16384) at the cost of a higher required GPU RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-GnxlXnDK7g"
   },
   "source": [
    "Pubmed's input data has a median token length of 2715 with the 90%-ile token length being 6101. The output data has a media token length of 171 with the 90%-ile token length being 352.${}^1$.\n",
    "\n",
    "Thus, we set the maximum input length to 8192 and the maximum output length to 512 to ensure that the model can attend to almost all input tokens is able to generate up to a large enough number of output tokens.\n",
    "\n",
    "In this notebook, we are only able to train on `batch_size=2` to prevent out-of-memory errors.\n",
    "\n",
    "---\n",
    "${}^1$ The data is taken from page 11 of [Big Bird: Transformers for Longer Sequences](https://arxiv.org/pdf/2007.14062.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Nbb24Uh-Y4xO"
   },
   "outputs": [],
   "source": [
    "max_input_length = 8192\n",
    "max_output_length = 512\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN_SAv1JE40f"
   },
   "source": [
    "Now, let's write down the input data processing function that will be used to map each data sample to the correct model format.\n",
    "As explained earlier `article` represents here our input data and `abstract` is the target data. The datasamples are thus tokenized up to the respective maximum lengths of 8192 and 512.\n",
    "\n",
    "In addition to the usual `attention_mask`, LED can make use of an additional `global_attention_mask` defining which input tokens are attended globally and which are attended only locally, just as it's the case of [Longformer](https://huggingface.co/transformers/model_doc/longformer.html). For more information on Longformer's self-attention, please take a look at the corresponding [docs](https://huggingface.co/transformers/model_doc/longformer.html#longformer-self-attention). For summarization, we follow recommendations of the [paper](https://arxiv.org/abs/2004.05150) and use global attention only for the very first token. Finally, we make sure that no loss is computed on padded tokens by setting their index to `-100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lEcAaZhNY8ge"
   },
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(\n",
    "        batch[\"article\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"abstract\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_output_length,\n",
    "    )\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    # create 0 global_attention_mask lists\n",
    "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
    "        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
    "    ]\n",
    "\n",
    "    # since above lists are references, the following line changes the 0 index for all samples\n",
    "    batch[\"global_attention_mask\"][0][0] = 1\n",
    "    batch[\"labels\"] = outputs.input_ids\n",
    "\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyseRmC5IcXj"
   },
   "source": [
    "For the sake of this notebook, we will reduce the training and validation data\n",
    "to a dummy dataset of sizes 250 and 25 respectively. For a full training run, those lines should be commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xMAkJfjCZKeE"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m))\n\u001b[1;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.select(range(250))\n",
    "val_dataset = val_dataset.select(range(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNzZZACtIoCD"
   },
   "source": [
    "Great, having defined the mapping function, let's preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "a7ad5edce9fb489a91af6674a98a0caf",
      "e2d46c6ae9504fad8d948ead80540bc7",
      "71d5805939554973bf5bda9857363e36",
      "39077a13f19f436cac1776cc764e216e",
      "986da3149afb4d6482ed4180496dd32e",
      "0bf8ff417a8e4c6e9a220773abba676c",
      "8c9c3df19abe46b0b72dc22acfe5e171",
      "c2c35eb741e84b4b86b86aea27e1f508"
     ]
    },
    "id": "8RClMjZOZCPO",
    "outputId": "a302dfc6-cf85-4711-fca7-4af1619a24ee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ad5edce9fb489a91af6674a98a0caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"article\", \"abstract\", \"section_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUtRFmgVIuHG"
   },
   "source": [
    "and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "ae2c5292d1bd438fbf1a7f8efb621f80",
      "91f2b5c6c08249c99f2ae9142de10944",
      "5a1a9126bc0d482fa74f3e31668597bc",
      "3d8bf464ab004bd9b845f40f85bb1fb0",
      "01ca2e35b6204de1bf4d0319b828e663",
      "05cbbad50c1f4fdebc0ba8b77b991858",
      "48ec7621dc694f329c9067064301558c",
      "cc779ed8d79e4a12903a66c6906f5ef4"
     ]
    },
    "id": "Gy_9DCocZD5G",
    "outputId": "d5cb67f7-c31b-4ca1-c715-2ab7d1d4c751"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2c5292d1bd438fbf1a7f8efb621f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataset = val_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"article\", \"abstract\", \"section_names\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evRRitZaIw9N"
   },
   "source": [
    "Finally, the datasets should be converted into the PyTorch format as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci2QYHCMZiNO"
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI-QHywgI6Hb"
   },
   "source": [
    "Alright, we're almost ready to start training. Let's load the model via the `AutoModelForSeq2SeqLM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZf_8QXJacIc"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNJQlLDKJHIK"
   },
   "source": [
    "We've decided to stick to the smaller model `\"allenai/led-base-16384\"` for the sake of this notebook. In addition, we directly enable gradient checkpointing and disable the caching mechanism to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "41067af6df2a43ab903274861380d244",
      "254daaf16ac744fb92023ff1c59fe1aa",
      "58d1f53bbb6f4e159adcb73eb214b206",
      "bdae6ca2cb8c496d8460d0b441cc4f9f",
      "651de13b87ee47828a59a991858fcd85",
      "2b3927f6a8c940e1b3f6c3a6ed7309f6",
      "3f5feb6631ad460f92e2608f8285dfa7",
      "1e31b789aefb455d8e44705f5e2c0803"
     ]
    },
    "id": "R-UfEo0Zadpl",
    "outputId": "bef87946-25f1-46fb-a004-7f9a07b2b275"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41067af6df2a43ab903274861380d244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=647693783.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQOaX6eRJXkM"
   },
   "source": [
    "During training, we want to evaluate the model on Rouge, the most common metric used in summarization, to make sure the model is indeed improving during training. For this, we set fitting generation parameters. We'll use beam search with a small beam of just 2 to save memory. Also, we force the model to generate at least 100 tokens, but no more than 512. In addition, some other generation parameters are set that have been found helpful for generation. For more information on those parameters, please take a look at the [docs](https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.generation_utils.GenerationMixin.generate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPnNi_tWaklV"
   },
   "outputs": [],
   "source": [
    "# set generate hyperparameters\n",
    "led.config.num_beams = 2\n",
    "led.config.max_length = 512\n",
    "led.config.min_length = 100\n",
    "led.config.length_penalty = 2.0\n",
    "led.config.early_stopping = True\n",
    "led.config.no_repeat_ngram_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7FTiwHrKSBA"
   },
   "source": [
    "Next, we also have to define the function the will compute the `\"rouge\"` score during evalution.\n",
    "\n",
    "Let's load the `\"rouge\"` metric from ðŸ¤—datasets and define the `compute_metrics(...)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "96509af3c841475fa2f6ed82d85a35e5",
      "107329ec56d24f4692d369776a411fdd",
      "473705461f674640b78998d5bf37adda",
      "ea97802771284e6c88cde3c1c2a79e96",
      "d4d51ded4ef2451f8ff29a88a3f2d30d",
      "706768c28a0741bcb3b2d4b92f30f99f",
      "fe5a412926e34c90a87d4d638c01a3c6",
      "9bdc02684cc144e786efe712b27a5988"
     ]
    },
    "id": "S5_rc9wUaBop",
    "outputId": "37372527-69a0-462d-9b3c-5a49565be1f0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96509af3c841475fa2f6ed82d85a35e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1955.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsytOIWVKqFz"
   },
   "source": [
    "The compute metrics function expects the generation output, called `pred.predictions` as well as the gold label, called `pred.label_ids`.\n",
    "\n",
    "Those tokens are decoded and consequently, the rouge score can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ahmf7mcZzU7"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
    "    )[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrX2gBnYLAna"
   },
   "source": [
    "Now, we're ready to start training. Let's import the `Seq2SeqTrainer` and `Seq2SeqTrainingArguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gq7CajIWaUo5"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga-fCOB4LI4W"
   },
   "source": [
    "In contrast to the usual `Trainer`, the `Seq2SeqTrainer` makes it possible to use the `generate()` function during evaluation. This should be enabled with `predict_with_generate=True`. Because our GPU RAM is limited, we make use of gradient accumulation by setting `gradient_accumulation_steps=4` to have an effective `batch_size` of 2 * 4 = 8.\n",
    "\n",
    "Other training arguments can be read upon in the [docs](https://huggingface.co/transformers/main_classes/trainer.html?highlight=trainingarguments#transformers.TrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMehwI4QZqB_"
   },
   "outputs": [],
   "source": [
    "# enable fp16 apex training\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    fp16=True,\n",
    "    output_dir=\"./\",\n",
    "    logging_steps=5,\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZCY-C5mLzXY"
   },
   "source": [
    "The training arguments, along with the model, tokenizer, datasets and the `compute_metrics` function can then be passed to the `Seq2SeqTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WPyTYO_JfHW"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=led,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZxSe_afL9TH"
   },
   "source": [
    "and we can start training. This will take about ~35min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "g4zkCpeQa2NN",
    "outputId": "9f816059-dd39-40aa-e2b2-388ad8ef8146"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='11' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/31 11:39 < 25:54, 0.01 it/s, Epoch 0.32/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:911: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  self.args.max_grad_norm,\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs1gYYb1MJOr"
   },
   "source": [
    "This completes the fine-tuning tutorial for LED. This training script with some small changes was used to train [this](https://huggingface.co/patrickvonplaten/led-large-16384-pubmed) checkpoint, called `\" patrickvonplaten/led-large-16384-pubmed\"` on a single GPU for ca. 3 days. Evaluating `\" patrickvonplaten/led-large-16384-pubmed\"` on Pubmed's test data gives a Rouge-2 score of **19.33** which is around 1 Rouge-2 point below SOTA performance on Pubmed.\n",
    "\n",
    "In the Appendix below, the condensed training and evaluation scripts that were used locally to finetune `\" patrickvonplaten/led-large-16384-pubmed\"` are attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_t9sjHha5T8"
   },
   "source": [
    "# **Appendix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv7edHocbDCD"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# è¼‰å…¥è³‡æ–™\n",
    "df = pd.read_csv('data/all_articles5-v2.csv')\n",
    "\n",
    "# é‡å‘½åæ¬„ä½\n",
    "df = df.rename(columns={\n",
    "    \"full_text\": \"article\",\n",
    "    \"abstract\": \"abstract\"\n",
    "})\n",
    "\n",
    "# å…ˆç§»é™¤ NaNï¼ŒæŽ¥è‘—éŽæ¿¾ç©ºå­—ä¸²ï¼Œç„¶å¾Œå¼·åˆ¶è½‰æˆ str\n",
    "df = df.dropna(subset=[\"article\", \"abstract\"])\n",
    "df = df[df[\"article\"].str.strip().astype(bool)]\n",
    "df = df[df[\"abstract\"].str.strip().astype(bool)]\n",
    "df[\"article\"] = df[\"article\"].astype(str)\n",
    "df[\"abstract\"] = df[\"abstract\"].astype(str)\n",
    "\n",
    "# åˆ‡åˆ†è³‡æ–™\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# è½‰æˆ Hugging Face Dataset æ ¼å¼ï¼ˆåŽ»æŽ‰ indexï¼‰\n",
    "pubmed_train = Dataset.from_pandas(train_df[[\"article\", \"abstract\"]].reset_index(drop=True))\n",
    "pubmed_val   = Dataset.from_pandas(val_df[[\"article\", \"abstract\"]].reset_index(drop=True))\n",
    "pubmed_test  = Dataset.from_pandas(test_df[[\"article\", \"abstract\"]].reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.7\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "print(dill.__version__)  # âœ… å¸Œæœ›çœ‹åˆ° 0.3.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting datasets==2.14.6\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /jet/home/slin23/.local/lib/python3.12/site-packages (from datasets==2.14.6) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (2.32.3)\n",
      "Collecting tqdm>=4.62.1 (from datasets==2.14.6)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: xxhash in /jet/home/slin23/.local/lib/python3.12/site-packages (from datasets==2.14.6) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /jet/home/slin23/.local/lib/python3.12/site-packages (from datasets==2.14.6) (0.70.16)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /jet/home/slin23/.local/lib/python3.12/site-packages (from datasets==2.14.6) (0.28.1)\n",
      "Requirement already satisfied: packaging in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from datasets==2.14.6) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from aiohttp->datasets==2.14.6) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from aiohttp->datasets==2.14.6) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from aiohttp->datasets==2.14.6) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from aiohttp->datasets==2.14.6) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from aiohttp->datasets==2.14.6) (1.11.0)\n",
      "Requirement already satisfied: filelock in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.14.6) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.14.6) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.14.6)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from pandas->datasets==2.14.6) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from pandas->datasets==2.14.6) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/packages/anaconda3-2024.10-1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.16.0)\n",
      "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Installing collected packages: tqdm, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.49.0\n",
      "    Uninstalling tqdm-4.49.0:\n",
      "      Successfully uninstalled tqdm-4.49.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.6\n",
      "    Uninstalling dill-0.3.6:\n",
      "      Successfully uninstalled dill-0.3.6\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.2.1\n",
      "    Uninstalling datasets-1.2.1:\n",
      "      Successfully uninstalled datasets-1.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2024.6.1 requires fsspec==2024.6.1.*, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.14.6 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets==2.14.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting dill==0.3.6\n",
      "  Downloading dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n",
      "Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Installing collected packages: dill\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "multiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.6 which is incompatible.\n",
      "evaluate 0.4.3 requires datasets>=2.0.0, but you have datasets 1.2.1 which is incompatible.\n",
      "evaluate 0.4.3 requires tqdm>=4.62.1, but you have tqdm 4.49.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dill-0.3.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dill==0.3.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9U3vpJxnOJiH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_58153/1477522231.py:11: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47ac5fc23834626ae8d188930f9a5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3098fcde438b46acb4d974228e871566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/slin23/.local/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/jet/home/slin23/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:651: UserWarning: Not enough free disk space to download the file. The expected file size is: 1839.48 MB. The target location /jet/home/slin23/.cache/huggingface/hub/models--patrickvonplaten--led-large-16384-pubmed/blobs only has 72.72 MB free disk space.\n",
      "  warnings.warn(\n",
      "/var/tmp/ipykernel_58153/1477522231.py:147: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a050634ca3a44b1af4da99cde79d2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  55%|#####5    | 1.02G/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='376' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 376/3750 1:53:45 < 17:06:12, 0.05 it/s, Epoch 0.30/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    ")\n",
    "\n",
    "# load rouge\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "pubmed_train = pubmed_train.select(range(10000))\n",
    "pubmed_val = pubmed_val.select(range(1000))\n",
    "pubmed_test = pubmed_val.select(range(1000))\n",
    "\n",
    "\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\")\n",
    "\n",
    "\n",
    "# max encoder length is 8192 for PubMed\n",
    "encoder_max_length = 8192\n",
    "decoder_max_length = 512\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(\n",
    "        batch[\"article\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=encoder_max_length,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"abstract\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=decoder_max_length,\n",
    "    )\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    # create 0 global_attention_mask lists\n",
    "    batch[\"global_attention_mask\"] = [\n",
    "        [1] + [0] * (len(input_ids) - 1)\n",
    "        for input_ids in batch[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    # since above lists are references, the following line changes the 0 index for all samples\n",
    "    batch[\"global_attention_mask\"][0][0] = 1\n",
    "    batch[\"labels\"] = outputs.input_ids\n",
    "\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "# map train data\n",
    "pubmed_train = pubmed_train.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"article\", \"abstract\"],\n",
    "    load_from_cache_file=False  # åŠ é€™è¡Œé¿å…å¯«å…¥ cache\n",
    ")\n",
    "\n",
    "# map val data\n",
    "pubmed_val = pubmed_val.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"article\", \"abstract\"],\n",
    "    load_from_cache_file=False  # åŠ é€™è¡Œé¿å…å¯«å…¥ cache\n",
    ")\n",
    "\n",
    "# set Python list to PyTorch tensor\n",
    "pubmed_train.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# set Python list to PyTorch tensor\n",
    "pubmed_val.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "# enable fp16 apex training\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    fp16=True,\n",
    "    fp16_backend=\"auto\",\n",
    "    output_dir=\"./\",\n",
    "    logging_steps=250,\n",
    "    eval_steps=5000,\n",
    "    save_steps=500,\n",
    "    warmup_steps=1500,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,\n",
    ")\n",
    "\n",
    "\n",
    "# compute Rouge score during validation\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
    "    )[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }\n",
    "\n",
    "\n",
    "# load model + enable gradient checkpointing & disable cache for checkpointing\n",
    "led = AutoModelForSeq2SeqLM.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\", gradient_checkpointing=True, use_cache=False)\n",
    "\n",
    "# set generate hyperparameters\n",
    "led.config.num_beams = 4\n",
    "led.config.max_length = 512\n",
    "led.config.min_length = 100\n",
    "led.config.length_penalty = 2.0\n",
    "led.config.early_stopping = True\n",
    "led.config.no_repeat_ngram_size = 3\n",
    "\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=led,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=pubmed_train,\n",
    "    eval_dataset=pubmed_val,\n",
    ")\n",
    "\n",
    "# start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFtGA4yibG2u",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pubmed\n",
    "# pubmed_test = load_dataset(\"scientific_papers\", \"pubmed\", ignore_verifications=True, split=\"test\")\n",
    "\n",
    "# load tokenizer\n",
    "# tokenizer = LEDTokenizer.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\")\n",
    "# model = LEDForConditionalGeneration.from_pretrained(\"patrickvonplaten/led-large-16384-pubmed\").to(\"cuda\").half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLM3niQqhEzP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "\n",
    "led.eval()\n",
    "\n",
    "\n",
    "def generate_answer(batch):\n",
    "  inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=8192, return_tensors=\"pt\", truncation=True)\n",
    "  input_ids = inputs_dict.input_ids.to(\"cuda\")\n",
    "  attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n",
    "  global_attention_mask = torch.zeros_like(attention_mask)\n",
    "  # put global attention on <s> token\n",
    "  global_attention_mask[:, 0] = 1\n",
    "\n",
    "  predicted_abstract_ids = led.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
    "  batch[\"predicted_abstract\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n",
    "  return batch\n",
    "\n",
    "\n",
    "result = pubmed_test.map(generate_answer, batched=True, batch_size=4)\n",
    "\n",
    "# load rouge\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "print(\"Result:\", rouge.compute(predictions=result[\"predicted_abstract\"], references=result[\"abstract\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ca2e35b6204de1bf4d0319b828e663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "05cbbad50c1f4fdebc0ba8b77b991858": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bf8ff417a8e4c6e9a220773abba676c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "107329ec56d24f4692d369776a411fdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e31b789aefb455d8e44705f5e2c0803": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "254daaf16ac744fb92023ff1c59fe1aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26a414921849456a90c57359ec1bcd29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "27e55c80741f4303948ee2187fc9dc84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe121869fe3c410f9f0355035a2f5a95",
       "IPY_MODEL_7392742aa0714f89ad05f4909fe4f04e"
      ],
      "layout": "IPY_MODEL_b3ceb8afd6dd467f9375004a95cfc6bc"
     }
    },
    "28d647bf76134a2b8dffb7c516c3e18f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b3927f6a8c940e1b3f6c3a6ed7309f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31b6f63eb7b142fc880e20348884a3cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39077a13f19f436cac1776cc764e216e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2c35eb741e84b4b86b86aea27e1f508",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8c9c3df19abe46b0b72dc22acfe5e171",
      "value": " 125/125 [00:09&lt;00:00, 13.41ba/s]"
     }
    },
    "3d8bf464ab004bd9b845f40f85bb1fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc779ed8d79e4a12903a66c6906f5ef4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_48ec7621dc694f329c9067064301558c",
      "value": " 13/13 [00:04&lt;00:00,  2.61ba/s]"
     }
    },
    "3f5feb6631ad460f92e2608f8285dfa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41067af6df2a43ab903274861380d244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58d1f53bbb6f4e159adcb73eb214b206",
       "IPY_MODEL_bdae6ca2cb8c496d8460d0b441cc4f9f"
      ],
      "layout": "IPY_MODEL_254daaf16ac744fb92023ff1c59fe1aa"
     }
    },
    "473705461f674640b78998d5bf37adda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_706768c28a0741bcb3b2d4b92f30f99f",
      "max": 1955,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4d51ded4ef2451f8ff29a88a3f2d30d",
      "value": 1955
     }
    },
    "48ec7621dc694f329c9067064301558c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58d1f53bbb6f4e159adcb73eb214b206": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b3927f6a8c940e1b3f6c3a6ed7309f6",
      "max": 647693783,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_651de13b87ee47828a59a991858fcd85",
      "value": 647693783
     }
    },
    "5a1a9126bc0d482fa74f3e31668597bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05cbbad50c1f4fdebc0ba8b77b991858",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01ca2e35b6204de1bf4d0319b828e663",
      "value": 13
     }
    },
    "629aaa73de364f60abaad1a667a93e0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "651de13b87ee47828a59a991858fcd85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "706768c28a0741bcb3b2d4b92f30f99f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71d5805939554973bf5bda9857363e36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bf8ff417a8e4c6e9a220773abba676c",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_986da3149afb4d6482ed4180496dd32e",
      "value": 125
     }
    },
    "7392742aa0714f89ad05f4909fe4f04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8df309486b4d48a794003c00db6cf674",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b3d4b5056c884b488753de076e9d883a",
      "value": " 456k/456k [00:00&lt;00:00, 623kB/s]"
     }
    },
    "8c9c3df19abe46b0b72dc22acfe5e171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8df309486b4d48a794003c00db6cf674": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f2b5c6c08249c99f2ae9142de10944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96509af3c841475fa2f6ed82d85a35e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_473705461f674640b78998d5bf37adda",
       "IPY_MODEL_ea97802771284e6c88cde3c1c2a79e96"
      ],
      "layout": "IPY_MODEL_107329ec56d24f4692d369776a411fdd"
     }
    },
    "986da3149afb4d6482ed4180496dd32e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "987634ba7143482a9e83b2458bdc6867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c42d012db3d04a80bb4ba96b9719471c",
       "IPY_MODEL_f2bfe910f06f4657a8b12cbe3c01d0dd"
      ],
      "layout": "IPY_MODEL_28d647bf76134a2b8dffb7c516c3e18f"
     }
    },
    "9bdc02684cc144e786efe712b27a5988": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9ec3a0b4bf4220964e4899bbc57f32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3654837bcea41feb5276522e1e303fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a45379ba9d814176a825fa5314d51616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a771005dce184befb9e944790b68c85c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7ad5edce9fb489a91af6674a98a0caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_71d5805939554973bf5bda9857363e36",
       "IPY_MODEL_39077a13f19f436cac1776cc764e216e"
      ],
      "layout": "IPY_MODEL_e2d46c6ae9504fad8d948ead80540bc7"
     }
    },
    "ae2c5292d1bd438fbf1a7f8efb621f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a1a9126bc0d482fa74f3e31668597bc",
       "IPY_MODEL_3d8bf464ab004bd9b845f40f85bb1fb0"
      ],
      "layout": "IPY_MODEL_91f2b5c6c08249c99f2ae9142de10944"
     }
    },
    "b3ceb8afd6dd467f9375004a95cfc6bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3d4b5056c884b488753de076e9d883a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bdae6ca2cb8c496d8460d0b441cc4f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e31b789aefb455d8e44705f5e2c0803",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3f5feb6631ad460f92e2608f8285dfa7",
      "value": " 648M/648M [00:20&lt;00:00, 31.7MB/s]"
     }
    },
    "c2c35eb741e84b4b86b86aea27e1f508": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3c556400c814a9082d6e271088c3ead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbca7f5762804be0b0e292b81d0c7e4e",
       "IPY_MODEL_e08d14bfc9d4413fbf1bdf95e4d50c61"
      ],
      "layout": "IPY_MODEL_a3654837bcea41feb5276522e1e303fd"
     }
    },
    "c42d012db3d04a80bb4ba96b9719471c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31b6f63eb7b142fc880e20348884a3cb",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26a414921849456a90c57359ec1bcd29",
      "value": 898822
     }
    },
    "cb36dd97ef21418f997ec9fda5553d92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cc779ed8d79e4a12903a66c6906f5ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2161cab5e0a4d42a44347f6fad2aec1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4d51ded4ef2451f8ff29a88a3f2d30d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dbca7f5762804be0b0e292b81d0c7e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_629aaa73de364f60abaad1a667a93e0e",
      "max": 1092,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a45379ba9d814176a825fa5314d51616",
      "value": 1092
     }
    },
    "e08d14bfc9d4413fbf1bdf95e4d50c61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a771005dce184befb9e944790b68c85c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9c9ec3a0b4bf4220964e4899bbc57f32",
      "value": " 1.09k/1.09k [00:00&lt;00:00, 1.44kB/s]"
     }
    },
    "e2d46c6ae9504fad8d948ead80540bc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6d31003abdd4eb0905110d869fad1a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea97802771284e6c88cde3c1c2a79e96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bdc02684cc144e786efe712b27a5988",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fe5a412926e34c90a87d4d638c01a3c6",
      "value": " 4.93k/? [00:00&lt;00:00, 12.5kB/s]"
     }
    },
    "f2bfe910f06f4657a8b12cbe3c01d0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6d31003abdd4eb0905110d869fad1a1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fd86b38ac6d14d4c81100035a6fc03ea",
      "value": " 899k/899k [00:02&lt;00:00, 414kB/s]"
     }
    },
    "fd86b38ac6d14d4c81100035a6fc03ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe121869fe3c410f9f0355035a2f5a95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2161cab5e0a4d42a44347f6fad2aec1",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb36dd97ef21418f997ec9fda5553d92",
      "value": 456318
     }
    },
    "fe5a412926e34c90a87d4d638c01a3c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
